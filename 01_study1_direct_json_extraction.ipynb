{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 1: Direct Raw JSON Extraction\n",
    "\n",
    "## Objective\n",
    "Test which method can extract eligibility criteria as **raw text** and compare against downloaded JSON from ClinicalTrials.gov.\n",
    "\n",
    "**No parsing into structured fields - just raw text extraction!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 0 ‚Äì Imports, base paths, trial IDs\n",
    "# ================================================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "from collections import OrderedDict\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# ---- Your trial IDs (20 AD clinical trials) ----\n",
    "# Import centralized trial list\n",
    "import sys\n",
    "sys.path.append('/Users/guoshuyan/Desktop/OpenAD')\n",
    "from trial_ids_20 import TRIAL_IDS_20\n",
    "\n",
    "TRIAL_IDS = TRIAL_IDS_20  # All 20 AD clinical trials\n",
    "\n",
    "# Alternative: Define directly if import doesn't work\n",
    "# TRIAL_IDS = [\n",
    "#     # Original 12 trials\n",
    "#     \"NCT01767311\", \"NCT02008357\", \"NCT02477800\", \"NCT02484547\",\n",
    "#     \"NCT03443973\", \"NCT03444870\", \"NCT03887455\", \"NCT04437511\",\n",
    "#     \"NCT04770220\", \"NCT04777396\", \"NCT05026866\", \"NCT05108922\",\n",
    "#     # Additional 8 trials (update after downloading)\n",
    "#     \"NCT04592341\", \"NCT04619420\", \"NCT04828122\", \"NCT04947636\",\n",
    "#     \"NCT05014540\", \"NCT05269394\", \"NCT05310008\", \"NCT05531656\"\n",
    "# ]\n",
    "\n",
    "# ---- Folders ----\n",
    "BASE_DIR   = \"/Users/guoshuyan/Desktop/OpenAD\"\n",
    "RAW_DATA   = os.path.join(BASE_DIR, \"Raw_data\")   # new v2 downloads\n",
    "RAW_JSON   = os.path.join(BASE_DIR, \"Raw_json\")   # your existing \"gold\"\n",
    "\n",
    "os.makedirs(RAW_DATA, exist_ok=True)\n",
    "os.makedirs(RAW_JSON, exist_ok=True)\n",
    "\n",
    "def text_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"Character-level similarity using SequenceMatcher (0‚Äì1).\"\"\"\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoshuyan/venv/te-ml-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 2 ‚Äì Imports, paths, trial IDs\n",
    "# ================================================================\n",
    "import os\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# --- Paths on your Mac ---\n",
    "BASE_DIR  = \"/Users/guoshuyan/Desktop/OpenAD\"\n",
    "RAW_JSON  = os.path.join(BASE_DIR, \"Raw_json\")   # your curated / gold JSONs\n",
    "RAW_DATA  = os.path.join(BASE_DIR, \"Raw_data\")   # v2 API JSON downloads\n",
    "\n",
    "# --- Make sure dirs exist (won't overwrite anything) ---\n",
    "os.makedirs(RAW_JSON, exist_ok=True)\n",
    "os.makedirs(RAW_DATA, exist_ok=True)\n",
    "\n",
    "# --- Trial IDs you want to compare ---\n",
    "TRIAL_IDS = [\n",
    "    \"NCT01767311\",\n",
    "    \"NCT02008357\",\n",
    "    \"NCT02477800\",\n",
    "    \"NCT02484547\",\n",
    "    \"NCT03443973\",\n",
    "    \"NCT03444870\",\n",
    "    \"NCT03887455\",\n",
    "    \"NCT04437511\",\n",
    "    \"NCT04770220\",\n",
    "    \"NCT04777396\",\n",
    "    \"NCT05026866\",\n",
    "    \"NCT05108922\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 3 ‚Äì Utilities: load JSON, flatten to keypath:text, etc.\n",
    "# ================================================================\n",
    "def load_json_if_exists(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load JSON file or return {} if it doesn't exist / fails.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading {path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def flatten_json(obj: Any, prefix: str = \"\") -> List[str]:\n",
    "    \"\"\"Recursively flatten a JSON object into structural lines.\"\"\"\n",
    "    lines: List[str] = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            new_prefix = f\"{prefix}.{k}\" if prefix else k\n",
    "            lines.extend(flatten_json(v, new_prefix))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, item in enumerate(obj):\n",
    "            new_prefix = f\"{prefix}[{i}]\"\n",
    "            lines.extend(flatten_json(item, new_prefix))\n",
    "    else:\n",
    "        val = str(obj).replace(\"\n",
    "\", \" \")\n",
    "        lines.append(f\"{prefix}: {val}\")\n",
    "    return lines\n",
    "\n",
    "\n",
    "def json_to_struct_text(json_obj: Dict[str, Any]) -> str:\n",
    "    \"\"\"Convert a JSON object into a single structural text string.\"\"\"\n",
    "    if not json_obj:\n",
    "        return \"\"\n",
    "    return \"\n",
    "\".join(flatten_json(json_obj))\n",
    "\n",
    "\n",
    "def char_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"Simple character-level similarity (0‚Äì1).\"\"\"\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def _value_to_text(value: Any) -> str:\n",
    "    \"\"\"Best-effort conversion of nested JSON values into readable text.\"\"\"\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "    if isinstance(value, str):\n",
    "        return value\n",
    "    if isinstance(value, dict):\n",
    "        for key in (\"textblock\", \"textBlock\", \"TextBlock\"):\n",
    "            text = value.get(key)\n",
    "            if isinstance(text, str):\n",
    "                return text\n",
    "        parts: List[str] = []\n",
    "        for v in value.values():\n",
    "            text = _value_to_text(v)\n",
    "            if text:\n",
    "                parts.append(text)\n",
    "        return \" \n",
    "\".join(parts)\n",
    "    if isinstance(value, (list, tuple, set)):\n",
    "        parts: List[str] = []\n",
    "        for item in value:\n",
    "            text = _value_to_text(item)\n",
    "            if text:\n",
    "                parts.append(text)\n",
    "        return \" \n",
    "\".join(parts)\n",
    "    return str(value)\n",
    "\n",
    "\n",
    "def _normalize_text(text: str) -> str:\n",
    "    text = (text or \"\").replace(\"\n",
    "\", \"\n",
    "\")\n",
    "    text = re.sub(r\"\n",
    "{3,}\", \"\n",
    "\n",
    "\", text)\n",
    "    text = re.sub(r\"[\t ]+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_eligibility_textblock(json_obj: Dict[str, Any]) -> str:\n",
    "    module = json_obj.get(\"protocolSection\", {}).get(\"eligibilityModule\", {})\n",
    "    return _normalize_text(_value_to_text(module.get(\"eligibilityCriteria\")))\n",
    "\n",
    "\n",
    "def extract_eligibility_profile(json_obj: Dict[str, Any]) -> str:\n",
    "    module = json_obj.get(\"protocolSection\", {}).get(\"eligibilityModule\", {})\n",
    "    pieces: List[str] = []\n",
    "    textblock = _normalize_text(_value_to_text(module.get(\"eligibilityCriteria\")))\n",
    "    if textblock:\n",
    "        pieces.append(f\"Eligibility criteria:\n",
    "{textblock}\")\n",
    "    field_labels = {\n",
    "        \"minimumAge\": \"Minimum age\",\n",
    "        \"maximumAge\": \"Maximum age\",\n",
    "        \"sex\": \"Sex\",\n",
    "        \"stdAges\": \"Standard ages\",\n",
    "        \"acceptsHealthyVolunteers\": \"Accepts healthy volunteers\",\n",
    "        \"studyPopulation\": \"Study population\",\n",
    "        \"samplingMethod\": \"Sampling method\",\n",
    "    }\n",
    "    for key, label in field_labels.items():\n",
    "        value = _normalize_text(_value_to_text(module.get(key)))\n",
    "        if value:\n",
    "            pieces.append(f\"{label}: {value}\")\n",
    "    return \"\n",
    "\n",
    "\".join(pieces).strip()\n",
    "\n",
    "\n",
    "EXTRACTION_METHODS = OrderedDict({\n",
    "    \"flattened_json\": json_to_struct_text,\n",
    "    \"eligibility_textblock\": extract_eligibility_textblock,\n",
    "    \"eligibility_profile\": extract_eligibility_profile,\n",
    "})\n",
    "\n",
    "EXTRACTION_LABELS = {\n",
    "    \"flattened_json\": \"Flattened JSON\",\n",
    "    \"eligibility_textblock\": \"Eligibility text block\",\n",
    "    \"eligibility_profile\": \"Eligibility + profile fields\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 5 ‚Äì Compute similarities for all trials and extraction methods\n",
    "# ================================================================\n",
    "rows: List[Dict[str, Any]] = []\n",
    "method_order = list(EXTRACTION_METHODS.keys())\n",
    "\n",
    "for tid in TRIAL_IDS:\n",
    "    gold_path = os.path.join(RAW_JSON, f\"{tid}.json\")\n",
    "    api_path = os.path.join(RAW_DATA, f\"{tid}.json\")\n",
    "\n",
    "    gold_json = load_json_if_exists(gold_path)\n",
    "    api_json = load_json_if_exists(api_path)\n",
    "\n",
    "    if not gold_json and not api_json:\n",
    "        print(f\"‚ö†Ô∏è Skipping {tid}: both gold and API JSON are empty / missing.\")\n",
    "        continue\n",
    "\n",
    "    gold_text = json_to_struct_text(gold_json)\n",
    "    gold_len = len(gold_text)\n",
    "\n",
    "    for method_name, extractor in EXTRACTION_METHODS.items():\n",
    "        method_text = extractor(api_json)\n",
    "        row: Dict[str, Any] = {\n",
    "            \"trial_id\": tid,\n",
    "            \"method\": method_name,\n",
    "            \"method_label\": EXTRACTION_LABELS.get(method_name, method_name),\n",
    "            \"gold_len\": gold_len,\n",
    "            \"method_len\": len(method_text),\n",
    "            \"char_sim\": char_similarity(gold_text, method_text),\n",
    "        }\n",
    "        for name, model in MODELS.items():\n",
    "            e_gold = embed(model, gold_text)\n",
    "            e_method = embed(model, method_text)\n",
    "            row[f\"{name}_cos\"] = cosine(e_gold, e_method)\n",
    "        rows.append(row)\n",
    "\n",
    "sim_df = pd.DataFrame(rows)\n",
    "if sim_df.empty:\n",
    "    print(\"No trials compared ‚Äì check that JSON files exist in both folders.\")\n",
    "else:\n",
    "    sim_df[\"len_ratio_method_over_gold\"] = np.where(\n",
    "        sim_df[\"gold_len\"].astype(float) > 0,\n",
    "        sim_df[\"method_len\"].astype(float) / sim_df[\"gold_len\"].astype(float),\n",
    "        np.nan,\n",
    "    )\n",
    "    sim_df[\"method\"] = pd.Categorical(sim_df[\"method\"], categories=method_order, ordered=True)\n",
    "    sim_df = sim_df.sort_values([\"trial_id\", \"method\"]).reset_index(drop=True)\n",
    "    print(\"üîç Multi-model embedding similarity summary (per trial √ó method):\")\n",
    "    display(sim_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Multi-model embedding similarity summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>gold_len</th>\n",
       "      <th>api_len</th>\n",
       "      <th>char_sim</th>\n",
       "      <th>miniLM_cos</th>\n",
       "      <th>mpnet_cos</th>\n",
       "      <th>bge_base_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT01767311</td>\n",
       "      <td>104027</td>\n",
       "      <td>104027</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02008357</td>\n",
       "      <td>844418</td>\n",
       "      <td>844418</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT02477800</td>\n",
       "      <td>765203</td>\n",
       "      <td>765198</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT02484547</td>\n",
       "      <td>742903</td>\n",
       "      <td>742903</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT03443973</td>\n",
       "      <td>534879</td>\n",
       "      <td>534879</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCT03444870</td>\n",
       "      <td>869861</td>\n",
       "      <td>869861</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NCT03887455</td>\n",
       "      <td>154889</td>\n",
       "      <td>154889</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCT04437511</td>\n",
       "      <td>497698</td>\n",
       "      <td>497698</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NCT04770220</td>\n",
       "      <td>62594</td>\n",
       "      <td>351362</td>\n",
       "      <td>0.294983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT04777396</td>\n",
       "      <td>196339</td>\n",
       "      <td>196339</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCT05026866</td>\n",
       "      <td>130912</td>\n",
       "      <td>130912</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NCT05108922</td>\n",
       "      <td>384732</td>\n",
       "      <td>384732</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trial_id  gold_len  api_len  char_sim  miniLM_cos  mpnet_cos  \\\n",
       "0   NCT01767311    104027   104027  0.999981         1.0   1.000000   \n",
       "1   NCT02008357    844418   844418  0.999998         1.0   1.000000   \n",
       "2   NCT02477800    765203   765198  0.999994         1.0   1.000000   \n",
       "3   NCT02484547    742903   742903  0.999997         1.0   1.000000   \n",
       "4   NCT03443973    534879   534879  0.999996         1.0   1.000000   \n",
       "5   NCT03444870    869861   869861  0.999998         1.0   1.000000   \n",
       "6   NCT03887455    154889   154889  0.999987         1.0   1.000000   \n",
       "7   NCT04437511    497698   497698  0.999996         1.0   1.000000   \n",
       "8   NCT04770220     62594   351362  0.294983         1.0   0.999981   \n",
       "9   NCT04777396    196339   196339  0.999990         1.0   1.000000   \n",
       "10  NCT05026866    130912   130912  0.999985         1.0   1.000000   \n",
       "11  NCT05108922    384732   384732  0.999995         1.0   1.000000   \n",
       "\n",
       "    bge_base_cos  \n",
       "0       1.000000  \n",
       "1       1.000000  \n",
       "2       1.000000  \n",
       "3       1.000000  \n",
       "4       1.000000  \n",
       "5       1.000000  \n",
       "6       1.000000  \n",
       "7       1.000000  \n",
       "8       0.999992  \n",
       "9       1.000000  \n",
       "10      1.000000  \n",
       "11      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 6 ‚Äì Visualize similarities across methods\n",
    "# ================================================================\n",
    "if sim_df.empty:\n",
    "    print(\"No trials compared ‚Äì run the previous cell first.\")\n",
    "else:\n",
    "    df = sim_df.copy()\n",
    "    method_order = list(EXTRACTION_METHODS.keys())\n",
    "    method_labels = [EXTRACTION_LABELS[m] for m in method_order]\n",
    "    metrics = [\"char_sim\"] + [f\"{name}_cos\" for name in MODELS]\n",
    "    metric_titles = {\"char_sim\": \"Character-level similarity\"}\n",
    "    for name in MODELS:\n",
    "        metric_titles[f\"{name}_cos\"] = f\"Embedding cosine similarity ‚Äì {name}\"\n",
    "\n",
    "    fig, axes = plt.subplots(len(metrics), 1, figsize=(14, 4 * len(metrics)), sharex=True)\n",
    "    if len(metrics) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        pivot = df.pivot(index=\"trial_id\", columns=\"method\", values=metric)\n",
    "        pivot = pivot[method_order]\n",
    "        pivot.columns = method_labels\n",
    "        pivot.plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_title(metric_titles.get(metric, metric), fontsize=14)\n",
    "        ax.set_ylabel(\"Similarity\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.legend(title=\"Extraction method\")\n",
    "\n",
    "    axes[-1].set_xlabel(\"Trial ID\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # optional: visualize method/gold length ratios\n",
    "    length_pivot = df.pivot(index=\"trial_id\", columns=\"method\", values=\"len_ratio_method_over_gold\")\n",
    "    length_pivot = length_pivot[method_order]\n",
    "    length_pivot.columns = method_labels\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    length_pivot.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Method length vs. curated gold (ratio)\", fontsize=14)\n",
    "    ax.set_ylabel(\"Length ratio (method / gold)\")\n",
    "    ax.legend(title=\"Extraction method\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Similarity between curated (Raw_json) and API v2 (Raw_data) CT.gov JSON per trial**  \n",
      "\n",
      "| Rank | Trial ID | Gold len | API len | API/Gold | Len bar | Char sim | miniLM | mpnet | bge_base | Mean cos |\n",
      "| ---: | :--- | ---: | ---: | ---: | :---: | ---: | ---: | ---: | ---: | ---: |\n",
      "| 3 | NCT01767311 | 104,027 | 104,027 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 3 | NCT02008357 | 844,418 | 844,418 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 1 | NCT02477800 | 765,203 | 765,198 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 9 | NCT02484547 | 742,903 | 742,903 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 5 | NCT03443973 | 534,879 | 534,879 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 9 | NCT03444870 | 869,861 | 869,861 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 9 | NCT03887455 | 154,889 | 154,889 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 1 | NCT04437511 | 497,698 | 497,698 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 12 | NCT04770220 | 62,594 | 351,362 | 5.613 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ | 0.295 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 5 | NCT04777396 | 196,339 | 196,339 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 5 | NCT05026866 | 130,912 | 130,912 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| 5 | NCT05108922 | 384,732 | 384,732 | 1.000 | ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñÆ‚ñØ‚ñØ‚ñØ‚ñØ‚ñØ | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "\n",
      "_Legend:_ **API/Gold** is size ratio; **Len bar** visualizes it (‚ñÆ = filled, ‚ñØ = empty; capped at 2√ó).\n",
      "Saved: similarity_table.md\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Publication-style MARKDOWN table for sim_df\n",
    "# ================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _bar(value, max_value=1.0, width=10):\n",
    "    \"\"\"Unicode bar for Markdown (no colors).\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    value = max(0.0, min(value, max_value))\n",
    "    filled = int(round((value / max_value) * width))\n",
    "    return \"‚ñÆ\" * filled + \"‚ñØ\" * (width - filled)\n",
    "\n",
    "\n",
    "def _fmt(v, nd=3):\n",
    "    return \"\" if pd.isna(v) else f\"{v:.{nd}f}\"\n",
    "\n",
    "\n",
    "def _fmt_int(v):\n",
    "    return \"\" if pd.isna(v) else f\"{int(v):,}\"\n",
    "\n",
    "\n",
    "def make_similarity_markdown(sim_df: pd.DataFrame, max_rows: int | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Build a clean Markdown table string from sim_df.\n",
    "    Columns:\n",
    "    Rank | trial_id | method | gold_len | method_len | ratio | len_bar | char_sim | <embeds...> | mean_cos\n",
    "    \"\"\"\n",
    "    df = sim_df.copy().sort_values([\"trial_id\", \"method\"]).reset_index(drop=True)\n",
    "\n",
    "    embedding_cols = [c for c in df.columns if c.endswith(\"_cos\")]\n",
    "    if embedding_cols:\n",
    "        df[\"mean_cos\"] = df[embedding_cols].mean(axis=1)\n",
    "    else:\n",
    "        df[\"mean_cos\"] = np.nan\n",
    "\n",
    "    df[\"len_ratio_method_over_gold\"] = np.where(\n",
    "        df[\"gold_len\"].astype(float) > 0,\n",
    "        df[\"method_len\"].astype(float) / df[\"gold_len\"].astype(float),\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    df[\"rank\"] = (-df[\"mean_cos\"]).rank(method=\"min\").astype(int)\n",
    "\n",
    "    header_cols = [\n",
    "        \"Rank\",\n",
    "        \"Trial ID\",\n",
    "        \"Method\",\n",
    "        \"Gold len\",\n",
    "        \"Method len\",\n",
    "        \"Method/Gold\",\n",
    "        \"Len bar\",\n",
    "        \"Char sim\",\n",
    "    ] + [c.replace(\"_cos\", \"\") for c in embedding_cols] + [\"Mean cos\"]\n",
    "\n",
    "    rows = []\n",
    "    it = df if max_rows is None else df.head(max_rows)\n",
    "    for _, r in it.iterrows():\n",
    "        ratio = r.get(\"len_ratio_method_over_gold\", np.nan)\n",
    "        row = [\n",
    "            str(r[\"rank\"]),\n",
    "            str(r[\"trial_id\"]),\n",
    "            str(r.get(\"method_label\", r[\"method\"])),\n",
    "            _fmt_int(r[\"gold_len\"]),\n",
    "            _fmt_int(r[\"method_len\"]),\n",
    "            _fmt(ratio, 3),\n",
    "            _bar(min(ratio, 2.0) if pd.notna(ratio) else np.nan, max_value=2.0, width=10),\n",
    "            _fmt(r.get(\"char_sim\", np.nan), 3),\n",
    "        ]\n",
    "        for c in embedding_cols:\n",
    "            row.append(_fmt(r[c], 3))\n",
    "        row.append(_fmt(r[\"mean_cos\"], 3))\n",
    "        rows.append(row)\n",
    "\n",
    "    aligns = [\"---:\", \":---\", \":---\", \"---:\", \"---:\", \"---:\", \":---:\", \"---:\"]         + [\"---:\"] * len(embedding_cols) + [\"---:\"]\n",
    "\n",
    "    md = []\n",
    "    md.append(\"**Similarity between curated (Raw_json) and API-derived extractions (multiple methods)**  \")\n",
    "    md.append(\"\")\n",
    "    md.append(\"| \" + \" | \".join(header_cols) + \" |\")\n",
    "    md.append(\"| \" + \" | \".join(aligns) + \" |\")\n",
    "    for row in rows:\n",
    "        md.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "\n",
    "    md.append(\"\n",
    "_Legend:_ Length bar caps at 2√ó gold length; multiple methods share the same gold reference text.\")\n",
    "    return \"\n",
    "\".join(md)\n",
    "\n",
    "\n",
    "md_table = make_similarity_markdown(sim_df)\n",
    "print(md_table)\n",
    "\n",
    "with open(\"similarity_table.md\", \"w\") as f:\n",
    "    f.write(md_table)\n",
    "print(\"Saved: similarity_table.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```text\n",
      " rank    trial_id  gold_len  api_len  char_sim  miniLM_cos  mpnet_cos  bge_base_cos  mean_cos\n",
      "    1 NCT02477800    765203   765198  0.999994    1.000000   1.000000      1.000000  1.000000\n",
      "    2 NCT04437511    497698   497698  0.999996    1.000000   1.000000      1.000000  1.000000\n",
      "    3 NCT01767311    104027   104027  0.999981    1.000000   1.000000      1.000000  1.000000\n",
      "    4 NCT02008357    844418   844418  0.999998    1.000000   1.000000      1.000000  1.000000\n",
      "    5 NCT03443973    534879   534879  0.999996    1.000000   1.000000      1.000000  1.000000\n",
      "    6 NCT04777396    196339   196339  0.999990    1.000000   1.000000      1.000000  1.000000\n",
      "    7 NCT05026866    130912   130912  0.999985    1.000000   1.000000      1.000000  1.000000\n",
      "    8 NCT05108922    384732   384732  0.999995    1.000000   1.000000      1.000000  1.000000\n",
      "    9 NCT02484547    742903   742903  0.999997    1.000000   1.000000      1.000000  1.000000\n",
      "   10 NCT03444870    869861   869861  0.999998    1.000000   1.000000      1.000000  1.000000\n",
      "   11 NCT03887455    154889   154889  0.999987    1.000000   1.000000      1.000000  1.000000\n",
      "   12 NCT04770220     62594   351362  0.294983    1.000000   0.999981      0.999992  0.999991\n",
      "```\n",
      "Saved similarity_summary.tsv and similarity_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Clean numeric table + save to TSV/CSV (no markdown formatting)\n",
    "# ================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = sim_df.copy().sort_values([\"trial_id\", \"method\"]).reset_index(drop=True)\n",
    "embedding_cols = [c for c in df.columns if c.endswith(\"_cos\")]\n",
    "\n",
    "df[\"mean_cos\"] = df[embedding_cols].mean(axis=1) if embedding_cols else np.nan\n",
    "df[\"len_ratio_method_over_gold\"] = np.where(\n",
    "    df[\"gold_len\"].astype(float) > 0,\n",
    "    df[\"method_len\"].astype(float) / df[\"gold_len\"].astype(float),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "df[\"rank\"] = (\n",
    "    df[\"mean_cos\"].rank(ascending=False, method=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "summary_cols = (\n",
    "    [\"rank\", \"trial_id\", \"method\", \"method_label\",\n",
    "     \"gold_len\", \"method_len\", \"len_ratio_method_over_gold\", \"char_sim\"]\n",
    "    + embedding_cols\n",
    "    + [\"mean_cos\"]\n",
    ")\n",
    "\n",
    "summary_df = df[summary_cols].sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "float_fmt = lambda x: f\"{x:.6f}\"\n",
    "print(\"```text\")\n",
    "print(summary_df.to_string(index=False, float_format=float_fmt))\n",
    "print(\"```\")\n",
    "\n",
    "summary_df.to_csv(\n",
    "    \"similarity_summary.tsv\",\n",
    "    sep=\"\t\",\n",
    "    index=False,\n",
    "    float_format=\"%.6f\",\n",
    ")\n",
    "summary_df.to_csv(\n",
    "    \"similarity_summary.csv\",\n",
    "    index=False,\n",
    "    float_format=\"%.6f\",\n",
    ")\n",
    "print(\"Saved similarity_summary.tsv and similarity_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using trials: ['NCT01767311', 'NCT02008357', 'NCT02477800', 'NCT02484547', 'NCT03443973', 'NCT03444870', 'NCT03887455', 'NCT04437511', 'NCT04770220', 'NCT04777396']\n",
      "Folders ready.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 1 ‚Äì Imports, paths, trial IDs\n",
    "# ================================================================\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from collections import OrderedDict\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---- 10 trial IDs ----\n",
    "TRIAL_IDS = [\n",
    "    \"NCT01767311\",\n",
    "    \"NCT02008357\",\n",
    "    \"NCT02477800\",\n",
    "    \"NCT02484547\",\n",
    "    \"NCT03443973\",\n",
    "    \"NCT03444870\",\n",
    "    \"NCT03887455\",\n",
    "    \"NCT04437511\",\n",
    "    \"NCT04770220\",\n",
    "    \"NCT04777396\",\n",
    "]\n",
    "\n",
    "print(\"Using trials:\", TRIAL_IDS)\n",
    "\n",
    "# ---- Folder structure (your Mac) ----\n",
    "BASE_DIR = \"/Users/guoshuyan/Desktop/OpenAD\"\n",
    "\n",
    "RAW_JSON  = os.path.join(BASE_DIR, \"Raw_json\")     # ground truth\n",
    "RAW_API_V2 = os.path.join(BASE_DIR, \"Raw_data\")    # API v2 JSON\n",
    "RAW_HTML   = os.path.join(BASE_DIR, \"Raw_html\")    # raw HTML pages\n",
    "\n",
    "os.makedirs(RAW_API_V2, exist_ok=True)\n",
    "os.makedirs(RAW_HTML, exist_ok=True)\n",
    "\n",
    "print(\"Folders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 2 ‚Äì Utility similarity + flattening functions\n",
    "# ================================================================\n",
    "def text_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"Character-level similarity in [0, 1].\"\"\"\n",
    "    a, b = (a or \"\").strip(), (b or \"\").strip()\n",
    "    if not a and not b: return 1.0\n",
    "    if not a or not b:  return 0.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def flatten_json(obj: Any, prefix: str = \"\") -> Dict[str, str]:\n",
    "    \"\"\"Flatten nested JSON fully.\"\"\"\n",
    "    out = {}\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            out.update(flatten_json(v, f\"{prefix}.{k}\" if prefix else k))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, v in enumerate(obj):\n",
    "            out.update(flatten_json(v, f\"{prefix}[{i}]\"))\n",
    "    else:\n",
    "        out[prefix or \"root\"] = \"\" if obj is None else str(obj)\n",
    "    return out\n",
    "\n",
    "\n",
    "def json_to_struct_text(obj: Dict[str, Any]) -> str:\n",
    "    \"\"\"Turn whole JSON into deterministic structured text.\"\"\"\n",
    "    flat = flatten_json(obj)\n",
    "    lines = [f\"{k}: {v}\" for k, v in sorted(flat.items())]\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 3 ‚Äì Safe I/O\n",
    "# ================================================================\n",
    "def load_json_if_exists(path: str) -> Dict[str, Any]:\n",
    "    if not os.path.exists(path): return {}\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def load_text_if_exists(path: str) -> str:\n",
    "    if not os.path.exists(path): return \"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download step complete.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 4 ‚Äì Download both raw documents (API v2 + HTML)\n",
    "# ================================================================\n",
    "CTGOV_V2_BASE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "\n",
    "def fetch_api_v2_json(tid: str):\n",
    "    url = f\"{CTGOV_V2_BASE}/{tid}\"\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è API v2 JSON not found for {tid}\")\n",
    "        return {}\n",
    "    return resp.json()\n",
    "\n",
    "def fetch_html(tid: str):\n",
    "    url = f\"https://clinicaltrials.gov/study/{tid}\"\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è HTML not found for {tid}\")\n",
    "        return \"\"\n",
    "    return resp.text\n",
    "\n",
    "for tid in TRIAL_IDS:\n",
    "    # API v2\n",
    "    p_json = os.path.join(RAW_API_V2, f\"{tid}.json\")\n",
    "    if not os.path.exists(p_json):\n",
    "        j = fetch_api_v2_json(tid)\n",
    "        if j:\n",
    "            with open(p_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(j, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # HTML\n",
    "    p_html = os.path.join(RAW_HTML, f\"{tid}.html\")\n",
    "    if not os.path.exists(p_html):\n",
    "        html = fetch_html(tid)\n",
    "        if html:\n",
    "            with open(p_html, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "\n",
    "print(\"Download step complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 5 ‚Äì Whole-document loaders (NO eligibility slicing)\n",
    "# ================================================================\n",
    "def gold_text(tid: str) -> str:\n",
    "    j = load_json_if_exists(os.path.join(RAW_JSON, f\"{tid}.json\"))\n",
    "    return json_to_struct_text(j) if j else \"\"\n",
    "\n",
    "def api_v2_text(tid: str) -> str:\n",
    "    j = load_json_if_exists(os.path.join(RAW_API_V2, f\"{tid}.json\"))\n",
    "    return json_to_struct_text(j) if j else \"\"\n",
    "\n",
    "def html_text(tid: str) -> str:\n",
    "    html = load_text_if_exists(os.path.join(RAW_HTML, f\"{tid}.html\"))\n",
    "    if not html: return \"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup.get_text(\"\\n\", strip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåü Using two extraction methods:\n",
      "- api_v2: API v2 JSON\n",
      "- html: HTML\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 6 ‚Äì Only TWO extraction systems\n",
    "# ================================================================\n",
    "EXTRACTION_SYSTEMS = OrderedDict({\n",
    "    \"api_v2\": {\n",
    "        \"label\": \"API v2 JSON\",\n",
    "        \"loader\": api_v2_text,\n",
    "    },\n",
    "    \"html\": {\n",
    "        \"label\": \"HTML\",\n",
    "        \"loader\": html_text,\n",
    "    },\n",
    "})\n",
    "\n",
    "print(\"üåü Using two extraction methods:\")\n",
    "for k, cfg in EXTRACTION_SYSTEMS.items():\n",
    "    print(f\"- {k}: {cfg['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 7 ‚Äì Embedding models (for similarity only)\n",
    "# ================================================================\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODELS = OrderedDict({\n",
    "    \"miniLM\": SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    \"mpnet\": SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\"),\n",
    "})\n",
    "\n",
    "def embed(model, text):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    return model.encode(text, convert_to_numpy=True)\n",
    "\n",
    "def cosine(a, b):\n",
    "    if a is None or b is None or a.size == 0 or b.size == 0: return np.nan\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0: return np.nan\n",
    "    return float(np.dot(a, b) / (na * nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_145cf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_145cf_level0_col0\" class=\"col_heading level0 col0\" >rank</th>\n",
       "      <th id=\"T_145cf_level0_col1\" class=\"col_heading level0 col1\" >trial_id</th>\n",
       "      <th id=\"T_145cf_level0_col2\" class=\"col_heading level0 col2\" >method_label</th>\n",
       "      <th id=\"T_145cf_level0_col3\" class=\"col_heading level0 col3\" >char_sim</th>\n",
       "      <th id=\"T_145cf_level0_col4\" class=\"col_heading level0 col4\" >mean_cos</th>\n",
       "      <th id=\"T_145cf_level0_col5\" class=\"col_heading level0 col5\" >gold_len</th>\n",
       "      <th id=\"T_145cf_level0_col6\" class=\"col_heading level0 col6\" >method_len</th>\n",
       "      <th id=\"T_145cf_level0_col7\" class=\"col_heading level0 col7\" >miniLM_cos</th>\n",
       "      <th id=\"T_145cf_level0_col8\" class=\"col_heading level0 col8\" >mpnet_cos</th>\n",
       "      <th id=\"T_145cf_level0_col9\" class=\"col_heading level0 col9\" >mean_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_145cf_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_145cf_row0_col1\" class=\"data row0 col1\" >NCT03887455</td>\n",
       "      <td id=\"T_145cf_row0_col2\" class=\"data row0 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row0_col3\" class=\"data row0 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row0_col4\" class=\"data row0 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row0_col5\" class=\"data row0 col5\" >154889</td>\n",
       "      <td id=\"T_145cf_row0_col6\" class=\"data row0 col6\" >154889</td>\n",
       "      <td id=\"T_145cf_row0_col7\" class=\"data row0 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row0_col8\" class=\"data row0 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row0_col9\" class=\"data row0 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_145cf_row1_col0\" class=\"data row1 col0\" >2.000000</td>\n",
       "      <td id=\"T_145cf_row1_col1\" class=\"data row1 col1\" >NCT01767311</td>\n",
       "      <td id=\"T_145cf_row1_col2\" class=\"data row1 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row1_col3\" class=\"data row1 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row1_col4\" class=\"data row1 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row1_col5\" class=\"data row1 col5\" >104027</td>\n",
       "      <td id=\"T_145cf_row1_col6\" class=\"data row1 col6\" >104027</td>\n",
       "      <td id=\"T_145cf_row1_col7\" class=\"data row1 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row1_col8\" class=\"data row1 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row1_col9\" class=\"data row1 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_145cf_row2_col0\" class=\"data row2 col0\" >3.000000</td>\n",
       "      <td id=\"T_145cf_row2_col1\" class=\"data row2 col1\" >NCT02477800</td>\n",
       "      <td id=\"T_145cf_row2_col2\" class=\"data row2 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row2_col3\" class=\"data row2 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row2_col4\" class=\"data row2 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row2_col5\" class=\"data row2 col5\" >765203</td>\n",
       "      <td id=\"T_145cf_row2_col6\" class=\"data row2 col6\" >765198</td>\n",
       "      <td id=\"T_145cf_row2_col7\" class=\"data row2 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row2_col8\" class=\"data row2 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row2_col9\" class=\"data row2 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_145cf_row3_col0\" class=\"data row3 col0\" >4.000000</td>\n",
       "      <td id=\"T_145cf_row3_col1\" class=\"data row3 col1\" >NCT02484547</td>\n",
       "      <td id=\"T_145cf_row3_col2\" class=\"data row3 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row3_col4\" class=\"data row3 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row3_col5\" class=\"data row3 col5\" >742903</td>\n",
       "      <td id=\"T_145cf_row3_col6\" class=\"data row3 col6\" >742903</td>\n",
       "      <td id=\"T_145cf_row3_col7\" class=\"data row3 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row3_col8\" class=\"data row3 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row3_col9\" class=\"data row3 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_145cf_row4_col0\" class=\"data row4 col0\" >5.000000</td>\n",
       "      <td id=\"T_145cf_row4_col1\" class=\"data row4 col1\" >NCT03443973</td>\n",
       "      <td id=\"T_145cf_row4_col2\" class=\"data row4 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row4_col3\" class=\"data row4 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row4_col5\" class=\"data row4 col5\" >534879</td>\n",
       "      <td id=\"T_145cf_row4_col6\" class=\"data row4 col6\" >534879</td>\n",
       "      <td id=\"T_145cf_row4_col7\" class=\"data row4 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row4_col8\" class=\"data row4 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row4_col9\" class=\"data row4 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_145cf_row5_col0\" class=\"data row5 col0\" >6.000000</td>\n",
       "      <td id=\"T_145cf_row5_col1\" class=\"data row5 col1\" >NCT03444870</td>\n",
       "      <td id=\"T_145cf_row5_col2\" class=\"data row5 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row5_col3\" class=\"data row5 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row5_col4\" class=\"data row5 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row5_col5\" class=\"data row5 col5\" >869861</td>\n",
       "      <td id=\"T_145cf_row5_col6\" class=\"data row5 col6\" >869861</td>\n",
       "      <td id=\"T_145cf_row5_col7\" class=\"data row5 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row5_col8\" class=\"data row5 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row5_col9\" class=\"data row5 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_145cf_row6_col0\" class=\"data row6 col0\" >7.000000</td>\n",
       "      <td id=\"T_145cf_row6_col1\" class=\"data row6 col1\" >NCT04437511</td>\n",
       "      <td id=\"T_145cf_row6_col2\" class=\"data row6 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row6_col3\" class=\"data row6 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row6_col4\" class=\"data row6 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row6_col5\" class=\"data row6 col5\" >497698</td>\n",
       "      <td id=\"T_145cf_row6_col6\" class=\"data row6 col6\" >497698</td>\n",
       "      <td id=\"T_145cf_row6_col7\" class=\"data row6 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row6_col8\" class=\"data row6 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row6_col9\" class=\"data row6 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_145cf_row7_col0\" class=\"data row7 col0\" >8.000000</td>\n",
       "      <td id=\"T_145cf_row7_col1\" class=\"data row7 col1\" >NCT04770220</td>\n",
       "      <td id=\"T_145cf_row7_col2\" class=\"data row7 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row7_col3\" class=\"data row7 col3\" >0.293</td>\n",
       "      <td id=\"T_145cf_row7_col4\" class=\"data row7 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row7_col5\" class=\"data row7 col5\" >62594</td>\n",
       "      <td id=\"T_145cf_row7_col6\" class=\"data row7 col6\" >351362</td>\n",
       "      <td id=\"T_145cf_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row7_col8\" class=\"data row7 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row7_col9\" class=\"data row7 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_145cf_row8_col0\" class=\"data row8 col0\" >9.000000</td>\n",
       "      <td id=\"T_145cf_row8_col1\" class=\"data row8 col1\" >NCT04777396</td>\n",
       "      <td id=\"T_145cf_row8_col2\" class=\"data row8 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row8_col3\" class=\"data row8 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row8_col4\" class=\"data row8 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row8_col5\" class=\"data row8 col5\" >196339</td>\n",
       "      <td id=\"T_145cf_row8_col6\" class=\"data row8 col6\" >196339</td>\n",
       "      <td id=\"T_145cf_row8_col7\" class=\"data row8 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row8_col9\" class=\"data row8 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_145cf_row9_col0\" class=\"data row9 col0\" >10.000000</td>\n",
       "      <td id=\"T_145cf_row9_col1\" class=\"data row9 col1\" >NCT02008357</td>\n",
       "      <td id=\"T_145cf_row9_col2\" class=\"data row9 col2\" >API v2 JSON (whole)</td>\n",
       "      <td id=\"T_145cf_row9_col3\" class=\"data row9 col3\" >1.000</td>\n",
       "      <td id=\"T_145cf_row9_col4\" class=\"data row9 col4\" >1.000</td>\n",
       "      <td id=\"T_145cf_row9_col5\" class=\"data row9 col5\" >844418</td>\n",
       "      <td id=\"T_145cf_row9_col6\" class=\"data row9 col6\" >844418</td>\n",
       "      <td id=\"T_145cf_row9_col7\" class=\"data row9 col7\" >1.000</td>\n",
       "      <td id=\"T_145cf_row9_col8\" class=\"data row9 col8\" >1.000</td>\n",
       "      <td id=\"T_145cf_row9_col9\" class=\"data row9 col9\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_145cf_row10_col0\" class=\"data row10 col0\" >11.000000</td>\n",
       "      <td id=\"T_145cf_row10_col1\" class=\"data row10 col1\" >NCT03887455</td>\n",
       "      <td id=\"T_145cf_row10_col2\" class=\"data row10 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row10_col3\" class=\"data row10 col3\" >0.001</td>\n",
       "      <td id=\"T_145cf_row10_col4\" class=\"data row10 col4\" >0.315</td>\n",
       "      <td id=\"T_145cf_row10_col5\" class=\"data row10 col5\" >154889</td>\n",
       "      <td id=\"T_145cf_row10_col6\" class=\"data row10 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row10_col7\" class=\"data row10 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row10_col8\" class=\"data row10 col8\" >0.477</td>\n",
       "      <td id=\"T_145cf_row10_col9\" class=\"data row10 col9\" >0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_145cf_row11_col0\" class=\"data row11 col0\" >12.000000</td>\n",
       "      <td id=\"T_145cf_row11_col1\" class=\"data row11 col1\" >NCT01767311</td>\n",
       "      <td id=\"T_145cf_row11_col2\" class=\"data row11 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row11_col3\" class=\"data row11 col3\" >0.001</td>\n",
       "      <td id=\"T_145cf_row11_col4\" class=\"data row11 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row11_col5\" class=\"data row11 col5\" >104027</td>\n",
       "      <td id=\"T_145cf_row11_col6\" class=\"data row11 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row11_col7\" class=\"data row11 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row11_col8\" class=\"data row11 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row11_col9\" class=\"data row11 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_145cf_row12_col0\" class=\"data row12 col0\" >13.000000</td>\n",
       "      <td id=\"T_145cf_row12_col1\" class=\"data row12 col1\" >NCT02477800</td>\n",
       "      <td id=\"T_145cf_row12_col2\" class=\"data row12 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row12_col3\" class=\"data row12 col3\" >0.000</td>\n",
       "      <td id=\"T_145cf_row12_col4\" class=\"data row12 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row12_col5\" class=\"data row12 col5\" >765203</td>\n",
       "      <td id=\"T_145cf_row12_col6\" class=\"data row12 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row12_col7\" class=\"data row12 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row12_col8\" class=\"data row12 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row12_col9\" class=\"data row12 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_145cf_row13_col0\" class=\"data row13 col0\" >14.000000</td>\n",
       "      <td id=\"T_145cf_row13_col1\" class=\"data row13 col1\" >NCT02484547</td>\n",
       "      <td id=\"T_145cf_row13_col2\" class=\"data row13 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row13_col3\" class=\"data row13 col3\" >0.000</td>\n",
       "      <td id=\"T_145cf_row13_col4\" class=\"data row13 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row13_col5\" class=\"data row13 col5\" >742903</td>\n",
       "      <td id=\"T_145cf_row13_col6\" class=\"data row13 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row13_col7\" class=\"data row13 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row13_col8\" class=\"data row13 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row13_col9\" class=\"data row13 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_145cf_row14_col0\" class=\"data row14 col0\" >15.000000</td>\n",
       "      <td id=\"T_145cf_row14_col1\" class=\"data row14 col1\" >NCT03443973</td>\n",
       "      <td id=\"T_145cf_row14_col2\" class=\"data row14 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row14_col3\" class=\"data row14 col3\" >0.001</td>\n",
       "      <td id=\"T_145cf_row14_col4\" class=\"data row14 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row14_col5\" class=\"data row14 col5\" >534879</td>\n",
       "      <td id=\"T_145cf_row14_col6\" class=\"data row14 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row14_col7\" class=\"data row14 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row14_col8\" class=\"data row14 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row14_col9\" class=\"data row14 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_145cf_row15_col0\" class=\"data row15 col0\" >16.000000</td>\n",
       "      <td id=\"T_145cf_row15_col1\" class=\"data row15 col1\" >NCT03444870</td>\n",
       "      <td id=\"T_145cf_row15_col2\" class=\"data row15 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row15_col3\" class=\"data row15 col3\" >0.000</td>\n",
       "      <td id=\"T_145cf_row15_col4\" class=\"data row15 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row15_col5\" class=\"data row15 col5\" >869861</td>\n",
       "      <td id=\"T_145cf_row15_col6\" class=\"data row15 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row15_col7\" class=\"data row15 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row15_col8\" class=\"data row15 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row15_col9\" class=\"data row15 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_145cf_row16_col0\" class=\"data row16 col0\" >17.000000</td>\n",
       "      <td id=\"T_145cf_row16_col1\" class=\"data row16 col1\" >NCT04770220</td>\n",
       "      <td id=\"T_145cf_row16_col2\" class=\"data row16 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row16_col3\" class=\"data row16 col3\" >0.004</td>\n",
       "      <td id=\"T_145cf_row16_col4\" class=\"data row16 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row16_col5\" class=\"data row16 col5\" >62594</td>\n",
       "      <td id=\"T_145cf_row16_col6\" class=\"data row16 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row16_col7\" class=\"data row16 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row16_col8\" class=\"data row16 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row16_col9\" class=\"data row16 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_145cf_row17_col0\" class=\"data row17 col0\" >18.000000</td>\n",
       "      <td id=\"T_145cf_row17_col1\" class=\"data row17 col1\" >NCT04777396</td>\n",
       "      <td id=\"T_145cf_row17_col2\" class=\"data row17 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row17_col3\" class=\"data row17 col3\" >0.001</td>\n",
       "      <td id=\"T_145cf_row17_col4\" class=\"data row17 col4\" >0.306</td>\n",
       "      <td id=\"T_145cf_row17_col5\" class=\"data row17 col5\" >196339</td>\n",
       "      <td id=\"T_145cf_row17_col6\" class=\"data row17 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row17_col7\" class=\"data row17 col7\" >0.153</td>\n",
       "      <td id=\"T_145cf_row17_col8\" class=\"data row17 col8\" >0.459</td>\n",
       "      <td id=\"T_145cf_row17_col9\" class=\"data row17 col9\" >0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_145cf_row18_col0\" class=\"data row18 col0\" >19.000000</td>\n",
       "      <td id=\"T_145cf_row18_col1\" class=\"data row18 col1\" >NCT04437511</td>\n",
       "      <td id=\"T_145cf_row18_col2\" class=\"data row18 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row18_col3\" class=\"data row18 col3\" >0.000</td>\n",
       "      <td id=\"T_145cf_row18_col4\" class=\"data row18 col4\" >0.294</td>\n",
       "      <td id=\"T_145cf_row18_col5\" class=\"data row18 col5\" >497698</td>\n",
       "      <td id=\"T_145cf_row18_col6\" class=\"data row18 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row18_col7\" class=\"data row18 col7\" >0.137</td>\n",
       "      <td id=\"T_145cf_row18_col8\" class=\"data row18 col8\" >0.452</td>\n",
       "      <td id=\"T_145cf_row18_col9\" class=\"data row18 col9\" >0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_145cf_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_145cf_row19_col0\" class=\"data row19 col0\" >20.000000</td>\n",
       "      <td id=\"T_145cf_row19_col1\" class=\"data row19 col1\" >NCT02008357</td>\n",
       "      <td id=\"T_145cf_row19_col2\" class=\"data row19 col2\" >HTML (whole)</td>\n",
       "      <td id=\"T_145cf_row19_col3\" class=\"data row19 col3\" >0.000</td>\n",
       "      <td id=\"T_145cf_row19_col4\" class=\"data row19 col4\" >0.277</td>\n",
       "      <td id=\"T_145cf_row19_col5\" class=\"data row19 col5\" >844418</td>\n",
       "      <td id=\"T_145cf_row19_col6\" class=\"data row19 col6\" >170</td>\n",
       "      <td id=\"T_145cf_row19_col7\" class=\"data row19 col7\" >0.159</td>\n",
       "      <td id=\"T_145cf_row19_col8\" class=\"data row19 col8\" >0.396</td>\n",
       "      <td id=\"T_145cf_row19_col9\" class=\"data row19 col9\" >0.277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14c4eda90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/guoshuyan/Desktop/OpenAD/summary_api_vs_html.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 9 ‚Äì Summary table (ranked, cleaned)\n",
    "# ================================================================\n",
    "embedding_cols = [c for c in sim_df.columns if c.endswith(\"_cos\")]\n",
    "\n",
    "# mean cosine across all embedding models\n",
    "sim_df[\"mean_cos\"] = sim_df[embedding_cols].mean(axis=1)\n",
    "\n",
    "# rank trials by best method similarity (higher mean_cos = better)\n",
    "sim_df[\"rank\"] = sim_df[\"mean_cos\"].rank(ascending=False, method=\"first\")\n",
    "\n",
    "# keep only the columns we care about\n",
    "cols_keep = [\n",
    "    \"rank\", \"trial_id\", \"method_label\",\n",
    "    \"char_sim\", \"mean_cos\",\n",
    "    \"gold_len\", \"method_len\",\n",
    "] + embedding_cols\n",
    "\n",
    "summary_df = (\n",
    "    sim_df[cols_keep]\n",
    "    .sort_values([\"rank\", \"trial_id\", \"method_label\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# nice display (rounded)\n",
    "display(\n",
    "    summary_df.style\n",
    "    .format({\n",
    "        \"char_sim\": \"{:.3f}\",\n",
    "        \"mean_cos\": \"{:.3f}\",\n",
    "        **{c: \"{:.3f}\" for c in embedding_cols}\n",
    "    })\n",
    ")\n",
    "\n",
    "summary_path = os.path.join(BASE_DIR, \"summary_api_vs_html.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(\"Saved:\", summary_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "te-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
